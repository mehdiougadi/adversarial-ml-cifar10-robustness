[src.model] 2026-02-16 16:55:09,216 - INFO - Starting model creation and summarization...
[src.model] 2026-02-16 16:55:09,216 - INFO - Initializing CNN model...
[src.model] 2026-02-16 16:55:09,222 - INFO - Model created successfully on device: cpu
[src.model] 2026-02-16 16:55:09,222 - INFO - Counting model parameters...
[src.model] 2026-02-16 16:55:09,223 - INFO - Total trainable parameters: 545,098
[src.model] 2026-02-16 16:55:09,223 - INFO - Saving model summary to file...
[src.model] 2026-02-16 16:55:09,224 - INFO - Model summary saved to results/model_summary.txt
[src.model] 2026-02-16 16:55:09,225 - INFO - Model creation and summarization completed!
[src.train_baseline] 2026-02-16 16:55:09,225 - INFO - Starting baseline training pipeline...
[src.train_baseline] 2026-02-16 16:55:09,225 - INFO - Loading CIFAR-10 dataset...
[src.train_baseline] 2026-02-16 16:55:11,195 - INFO - Training samples: 50000
[src.train_baseline] 2026-02-16 16:55:11,195 - INFO - Test samples: 10000
[src.train_baseline] 2026-02-16 16:55:11,196 - INFO - Splitting dataset into train/val/test...
[src.train_baseline] 2026-02-16 16:55:11,200 - INFO - Train size: 35000
[src.train_baseline] 2026-02-16 16:55:11,205 - INFO - Validation size: 7500
[src.train_baseline] 2026-02-16 16:55:11,210 - INFO - Test size: 7500
[src.train_baseline] 2026-02-16 16:55:11,211 - INFO - Creating data loaders...
[src.train_baseline] 2026-02-16 16:55:11,212 - INFO - Batch size: 64
[src.train_baseline] 2026-02-16 16:55:11,212 - INFO - Starting model training...
[src.train_baseline] 2026-02-16 16:55:40,309 - INFO - Epoch [1/5] - Train Loss: 1.4056, Train Acc: 49.81%, Val Loss: 1.1091, Val Acc: 59.88%
[src.train_baseline] 2026-02-16 16:56:09,165 - INFO - Epoch [2/5] - Train Loss: 1.0080, Train Acc: 64.61%, Val Loss: 0.9233, Val Acc: 67.39%
[src.train_baseline] 2026-02-16 16:56:37,551 - INFO - Epoch [3/5] - Train Loss: 0.8398, Train Acc: 70.54%, Val Loss: 0.8890, Val Acc: 68.24%
[src.train_baseline] 2026-02-16 16:57:06,462 - INFO - Epoch [4/5] - Train Loss: 0.7213, Train Acc: 74.85%, Val Loss: 0.8728, Val Acc: 69.53%
[src.train_baseline] 2026-02-16 16:57:35,732 - INFO - Epoch [5/5] - Train Loss: 0.6030, Train Acc: 79.05%, Val Loss: 0.8761, Val Acc: 70.35%
[src.train_baseline] 2026-02-16 16:57:35,733 - INFO - Model training completed!
[src.train_baseline] 2026-02-16 16:57:35,733 - INFO - Evaluating model on test set...
[src.train_baseline] 2026-02-16 16:57:39,228 - INFO - Test Accuracy: 0.6983
[src.train_baseline] 2026-02-16 16:57:39,228 - INFO - Test Precision: 0.7061
[src.train_baseline] 2026-02-16 16:57:39,229 - INFO - Test Recall: 0.6983
[src.train_baseline] 2026-02-16 16:57:39,229 - INFO - Test F1-Score: 0.6970
[src.train_baseline] 2026-02-16 16:57:39,229 - INFO - Saving results to file...
[src.train_baseline] 2026-02-16 16:57:39,231 - INFO - Results saved to results/baseline_results.txt
[src.train_baseline] 2026-02-16 16:57:39,232 - INFO - Saving trained model...
[src.train_baseline] 2026-02-16 16:57:39,239 - INFO - Model saved to results\pth_files\baseline_model.pth
[src.train_baseline] 2026-02-16 16:57:39,240 - INFO - Baseline training pipeline completed!
[src.fgsm_attack] 2026-02-16 16:57:39,253 - INFO - Starting FGSM Attack Pipeline...
[src.fgsm_attack] 2026-02-16 16:57:40,191 - INFO - Testing FGSM with Epsilon = 0.0
[src.fgsm_attack] 2026-02-16 16:57:40,191 - INFO - Generating adversarial examples with epsilon=0.0...
[src.fgsm_attack] 2026-02-16 16:57:48,855 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 16:57:48,855 - INFO - Evaluating FGSM attack with epsilon=0.0...
[src.fgsm_attack] 2026-02-16 16:57:48,891 - INFO - Clean Accuracy: 0.6947
[src.fgsm_attack] 2026-02-16 16:57:48,891 - INFO - Adversarial Accuracy: 0.3408
[src.fgsm_attack] 2026-02-16 16:57:48,892 - INFO - Accuracy Drop: 0.3539
[src.fgsm_attack] 2026-02-16 16:57:48,892 - INFO - Testing FGSM with Epsilon = 0.01
[src.fgsm_attack] 2026-02-16 16:57:48,892 - INFO - Generating adversarial examples with epsilon=0.01...
[src.fgsm_attack] 2026-02-16 16:57:57,630 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 16:57:57,632 - INFO - Evaluating FGSM attack with epsilon=0.01...
[src.fgsm_attack] 2026-02-16 16:57:57,672 - INFO - Clean Accuracy: 0.6947
[src.fgsm_attack] 2026-02-16 16:57:57,673 - INFO - Adversarial Accuracy: 0.3167
[src.fgsm_attack] 2026-02-16 16:57:57,673 - INFO - Accuracy Drop: 0.3780
[src.fgsm_attack] 2026-02-16 16:57:57,724 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 16:57:58,975 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.01.png
[src.fgsm_attack] 2026-02-16 16:57:58,976 - INFO - Testing FGSM with Epsilon = 0.05
[src.fgsm_attack] 2026-02-16 16:57:58,976 - INFO - Generating adversarial examples with epsilon=0.05...
[src.fgsm_attack] 2026-02-16 16:58:07,823 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 16:58:07,825 - INFO - Evaluating FGSM attack with epsilon=0.05...
[src.fgsm_attack] 2026-02-16 16:58:07,864 - INFO - Clean Accuracy: 0.6947
[src.fgsm_attack] 2026-02-16 16:58:07,865 - INFO - Adversarial Accuracy: 0.2354
[src.fgsm_attack] 2026-02-16 16:58:07,865 - INFO - Accuracy Drop: 0.4593
[src.fgsm_attack] 2026-02-16 16:58:07,926 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 16:58:09,146 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.05.png
[src.fgsm_attack] 2026-02-16 16:58:09,147 - INFO - Testing FGSM with Epsilon = 0.1
[src.fgsm_attack] 2026-02-16 16:58:09,147 - INFO - Generating adversarial examples with epsilon=0.1...
[src.fgsm_attack] 2026-02-16 16:58:18,097 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 16:58:18,099 - INFO - Evaluating FGSM attack with epsilon=0.1...
[src.fgsm_attack] 2026-02-16 16:58:18,131 - INFO - Clean Accuracy: 0.6947
[src.fgsm_attack] 2026-02-16 16:58:18,131 - INFO - Adversarial Accuracy: 0.1642
[src.fgsm_attack] 2026-02-16 16:58:18,131 - INFO - Accuracy Drop: 0.5305
[src.fgsm_attack] 2026-02-16 16:58:18,194 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 16:58:19,375 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.1.png
[src.fgsm_attack] 2026-02-16 16:58:19,375 - INFO - Testing FGSM with Epsilon = 0.2
[src.fgsm_attack] 2026-02-16 16:58:19,376 - INFO - Generating adversarial examples with epsilon=0.2...
[src.fgsm_attack] 2026-02-16 16:58:28,395 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 16:58:28,397 - INFO - Evaluating FGSM attack with epsilon=0.2...
[src.fgsm_attack] 2026-02-16 16:58:28,424 - INFO - Clean Accuracy: 0.6947
[src.fgsm_attack] 2026-02-16 16:58:28,424 - INFO - Adversarial Accuracy: 0.0968
[src.fgsm_attack] 2026-02-16 16:58:28,424 - INFO - Accuracy Drop: 0.5979
[src.fgsm_attack] 2026-02-16 16:58:28,493 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 16:58:29,710 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.2.png
[src.fgsm_attack] 2026-02-16 16:58:29,711 - INFO - Creating epsilon analysis plot...
[src.fgsm_attack] 2026-02-16 16:58:30,052 - INFO - Epsilon analysis plot saved to results/fgsm_figures/fgsm_epsilon_analysis.png
[src.fgsm_attack] 2026-02-16 16:58:30,053 - INFO - Saving FGSM results to file...
[src.fgsm_attack] 2026-02-16 16:58:30,054 - INFO - FGSM results saved to results/fgsm_results.txt
[src.fgsm_attack] 2026-02-16 16:58:30,054 - INFO - FGSM Attack Pipeline Completed!
[src.pgd_attack] 2026-02-16 16:58:30,071 - INFO - Starting PGD Attack Pipeline...
[src.pgd_attack] 2026-02-16 16:58:31,006 - INFO - Testing PGD with Epsilon = 0.0
[src.pgd_attack] 2026-02-16 16:58:31,007 - INFO - Generating PGD adversarial examples with epsilon=0.0, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 16:59:18,235 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 16:59:18,235 - INFO - Evaluating PGD attack with epsilon=0.0...
[src.pgd_attack] 2026-02-16 16:59:18,275 - INFO - Clean Accuracy: 0.6947
[src.pgd_attack] 2026-02-16 16:59:18,275 - INFO - Robust Accuracy (PGD): 0.3408
[src.pgd_attack] 2026-02-16 16:59:18,275 - INFO - Accuracy Drop: 0.3539
[src.pgd_attack] 2026-02-16 16:59:18,276 - INFO - Testing PGD with Epsilon = 0.01
[src.pgd_attack] 2026-02-16 16:59:18,276 - INFO - Generating PGD adversarial examples with epsilon=0.01, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 17:00:06,617 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 17:00:06,619 - INFO - Evaluating PGD attack with epsilon=0.01...
[src.pgd_attack] 2026-02-16 17:00:06,659 - INFO - Clean Accuracy: 0.6947
[src.pgd_attack] 2026-02-16 17:00:06,659 - INFO - Robust Accuracy (PGD): 0.2839
[src.pgd_attack] 2026-02-16 17:00:06,659 - INFO - Accuracy Drop: 0.4108
[src.pgd_attack] 2026-02-16 17:00:06,943 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 17:00:08,277 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.01.png
[src.pgd_attack] 2026-02-16 17:00:08,278 - INFO - Testing PGD with Epsilon = 0.03
[src.pgd_attack] 2026-02-16 17:00:08,278 - INFO - Generating PGD adversarial examples with epsilon=0.03, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 17:00:57,103 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 17:00:57,105 - INFO - Evaluating PGD attack with epsilon=0.03...
[src.pgd_attack] 2026-02-16 17:00:57,145 - INFO - Clean Accuracy: 0.6947
[src.pgd_attack] 2026-02-16 17:00:57,146 - INFO - Robust Accuracy (PGD): 0.1871
[src.pgd_attack] 2026-02-16 17:00:57,146 - INFO - Accuracy Drop: 0.5076
[src.pgd_attack] 2026-02-16 17:00:57,481 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 17:00:58,985 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.03.png
[src.pgd_attack] 2026-02-16 17:00:58,985 - INFO - Testing PGD with Epsilon = 0.05
[src.pgd_attack] 2026-02-16 17:00:58,986 - INFO - Generating PGD adversarial examples with epsilon=0.05, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 17:01:47,856 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 17:01:47,857 - INFO - Evaluating PGD attack with epsilon=0.05...
[src.pgd_attack] 2026-02-16 17:01:47,894 - INFO - Clean Accuracy: 0.6947
[src.pgd_attack] 2026-02-16 17:01:47,894 - INFO - Robust Accuracy (PGD): 0.1261
[src.pgd_attack] 2026-02-16 17:01:47,894 - INFO - Accuracy Drop: 0.5686
[src.pgd_attack] 2026-02-16 17:01:48,216 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 17:01:49,431 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.05.png
[src.pgd_attack] 2026-02-16 17:01:49,431 - INFO - Creating PGD epsilon analysis plot...
[src.pgd_attack] 2026-02-16 17:01:49,736 - INFO - PGD epsilon analysis plot saved to results/pgd_figures/pgd_epsilon_analysis.png
[src.pgd_attack] 2026-02-16 17:01:49,737 - INFO - Saving PGD results to file...
[src.pgd_attack] 2026-02-16 17:01:49,738 - INFO - PGD results saved to results/pgd_results.txt
[src.pgd_attack] 2026-02-16 17:01:49,738 - INFO - PGD Attack Pipeline Completed!
[src.poisoning_attack] 2026-02-16 17:01:49,756 - INFO - Starting Data Poisoning Attack Pipeline...
[src.poisoning_attack] 2026-02-16 17:01:49,760 - WARNING - Could not load baseline accuracy, will use 0% poisoning as baseline
[src.poisoning_attack] 2026-02-16 17:01:49,760 - INFO - Testing with 0.0% label poisoning
[src.poisoning_attack] 2026-02-16 17:01:49,760 - INFO - Loading CIFAR-10 with 0.0% poisoning...
[src.poisoning_attack] 2026-02-16 17:02:08,145 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 17:02:08,146 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 17:02:08,146 - INFO - Test size: 7500
[src.poisoning_attack] 2026-02-16 17:02:08,174 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 17:02:37,327 - INFO - Epoch [1/5] - Train Loss: 0.5064, Train Acc: 82.26%, Val Loss: 0.8759, Val Acc: 70.60%
[src.poisoning_attack] 2026-02-16 17:03:06,728 - INFO - Epoch [2/5] - Train Loss: 0.4004, Train Acc: 86.11%, Val Loss: 0.9528, Val Acc: 70.73%
[src.poisoning_attack] 2026-02-16 17:03:36,208 - INFO - Epoch [3/5] - Train Loss: 0.3239, Train Acc: 88.81%, Val Loss: 0.9929, Val Acc: 70.37%
[src.poisoning_attack] 2026-02-16 17:04:05,793 - INFO - Epoch [4/5] - Train Loss: 0.2462, Train Acc: 91.65%, Val Loss: 1.1408, Val Acc: 69.63%
[src.poisoning_attack] 2026-02-16 17:04:35,365 - INFO - Epoch [5/5] - Train Loss: 0.1931, Train Acc: 93.50%, Val Loss: 1.2965, Val Acc: 69.53%
[src.poisoning_attack] 2026-02-16 17:04:35,366 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 17:04:35,366 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 17:04:38,869 - INFO - Test Accuracy: 0.6956
[src.poisoning_attack] 2026-02-16 17:04:38,869 - INFO - Test Precision: 0.7066
[src.poisoning_attack] 2026-02-16 17:04:38,870 - INFO - Test Recall: 0.6956
[src.poisoning_attack] 2026-02-16 17:04:38,870 - INFO - Test F1-Score: 0.6994
[src.poisoning_attack] 2026-02-16 17:04:38,877 - INFO - Model saved to results\pth_files\poisoned_model_0pct.pth
[src.poisoning_attack] 2026-02-16 17:04:38,878 - INFO - Testing with 5.0% label poisoning
[src.poisoning_attack] 2026-02-16 17:04:38,878 - INFO - Loading CIFAR-10 with 5.0% poisoning...
[src.poisoning_attack] 2026-02-16 17:04:56,849 - INFO - Flipping 5.0% of labels...
[src.poisoning_attack] 2026-02-16 17:04:57,097 - INFO - Successfully flipped 1750 labels out of 35000
[src.poisoning_attack] 2026-02-16 17:04:57,098 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 17:04:57,098 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 17:04:57,099 - INFO - Test size: 7500
[src.poisoning_attack] 2026-02-16 17:04:57,111 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 17:05:14,454 - INFO - Epoch [1/5] - Train Loss: 0.6544, Train Acc: 87.94%, Val Loss: 1.0048, Val Acc: 67.87%
[src.poisoning_attack] 2026-02-16 17:05:31,766 - INFO - Epoch [2/5] - Train Loss: 0.4858, Train Acc: 90.42%, Val Loss: 1.0849, Val Acc: 67.83%
[src.poisoning_attack] 2026-02-16 17:05:49,093 - INFO - Epoch [3/5] - Train Loss: 0.3878, Train Acc: 91.51%, Val Loss: 1.1558, Val Acc: 67.63%
[src.poisoning_attack] 2026-02-16 17:06:06,395 - INFO - Epoch [4/5] - Train Loss: 0.2988, Train Acc: 92.73%, Val Loss: 1.3118, Val Acc: 65.87%
[src.poisoning_attack] 2026-02-16 17:06:23,506 - INFO - Epoch [5/5] - Train Loss: 0.2195, Train Acc: 94.44%, Val Loss: 1.5140, Val Acc: 64.91%
[src.poisoning_attack] 2026-02-16 17:06:23,506 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 17:06:23,506 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 17:06:27,250 - INFO - Test Accuracy: 0.6505
[src.poisoning_attack] 2026-02-16 17:06:27,250 - INFO - Test Precision: 0.6570
[src.poisoning_attack] 2026-02-16 17:06:27,251 - INFO - Test Recall: 0.6505
[src.poisoning_attack] 2026-02-16 17:06:27,251 - INFO - Test F1-Score: 0.6471
[src.poisoning_attack] 2026-02-16 17:06:27,265 - INFO - Model saved to results\pth_files\poisoned_model_5pct.pth
[src.poisoning_attack] 2026-02-16 17:06:27,265 - INFO - Testing with 15.0% label poisoning
[src.poisoning_attack] 2026-02-16 17:06:27,265 - INFO - Loading CIFAR-10 with 15.0% poisoning...
[src.poisoning_attack] 2026-02-16 17:06:45,913 - INFO - Flipping 15.0% of labels...
[src.poisoning_attack] 2026-02-16 17:06:46,196 - INFO - Successfully flipped 5250 labels out of 35000
[src.poisoning_attack] 2026-02-16 17:06:46,197 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 17:06:46,198 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 17:06:46,198 - INFO - Test size: 7500
[src.poisoning_attack] 2026-02-16 17:06:46,232 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 17:07:03,588 - INFO - Epoch [1/5] - Train Loss: 1.0629, Train Acc: 79.61%, Val Loss: 1.1160, Val Acc: 64.69%
[src.poisoning_attack] 2026-02-16 17:07:21,213 - INFO - Epoch [2/5] - Train Loss: 0.8256, Train Acc: 82.49%, Val Loss: 1.1573, Val Acc: 64.31%
[src.poisoning_attack] 2026-02-16 17:07:38,536 - INFO - Epoch [3/5] - Train Loss: 0.6771, Train Acc: 84.29%, Val Loss: 1.2354, Val Acc: 63.73%
[src.poisoning_attack] 2026-02-16 17:07:58,129 - INFO - Epoch [4/5] - Train Loss: 0.5361, Train Acc: 86.49%, Val Loss: 1.3556, Val Acc: 61.44%
[src.poisoning_attack] 2026-02-16 17:08:22,306 - INFO - Epoch [5/5] - Train Loss: 0.4073, Train Acc: 88.85%, Val Loss: 1.6085, Val Acc: 59.88%
[src.poisoning_attack] 2026-02-16 17:08:22,307 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 17:08:22,309 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 17:08:27,303 - INFO - Test Accuracy: 0.5956
[src.poisoning_attack] 2026-02-16 17:08:27,304 - INFO - Test Precision: 0.6078
[src.poisoning_attack] 2026-02-16 17:08:27,304 - INFO - Test Recall: 0.5956
[src.poisoning_attack] 2026-02-16 17:08:27,304 - INFO - Test F1-Score: 0.5987
[src.poisoning_attack] 2026-02-16 17:08:27,311 - INFO - Model saved to results\pth_files\poisoned_model_15pct.pth
[src.poisoning_attack] 2026-02-16 17:08:27,312 - INFO - Creating poisoning comparison plot...
[src.poisoning_attack] 2026-02-16 17:08:27,752 - INFO - Poisoning comparison plot saved to results/poisoning_figures/poisoning_comparison.png
[src.poisoning_attack] 2026-02-16 17:08:27,752 - INFO - Creating training curves comparison...
[src.poisoning_attack] 2026-02-16 17:08:28,573 - INFO - Training curves saved to results/poisoning_figures/training_curves.png
[src.poisoning_attack] 2026-02-16 17:08:28,573 - INFO - Saving poisoning results to file...
[src.poisoning_attack] 2026-02-16 17:08:28,575 - INFO - Poisoning results saved to results/poisoning_results.txt
[src.poisoning_attack] 2026-02-16 17:08:28,575 - INFO - Data Poisoning Attack Pipeline Completed!
[src.adversarial_training] 2026-02-16 17:08:28,625 - INFO - Starting Adversarial Training Defense Pipeline...
[src.adversarial_training] 2026-02-16 17:08:28,626 - INFO - Loading CIFAR-10 dataset for adversarial training...
[src.adversarial_training] 2026-02-16 17:08:29,995 - INFO - Train size: 35000
[src.adversarial_training] 2026-02-16 17:08:29,996 - INFO - Validation size: 7500
[src.adversarial_training] 2026-02-16 17:08:29,996 - INFO - Test size: 7500
[src.adversarial_training] 2026-02-16 17:08:29,997 - INFO - Evaluating baseline model...
[src.adversarial_training] 2026-02-16 17:08:29,997 - INFO - Evaluating on clean test data...
[src.adversarial_training] 2026-02-16 17:08:34,746 - INFO - Clean Accuracy: 0.5956
[src.adversarial_training] 2026-02-16 17:08:34,747 - INFO - Precision: 0.6078
[src.adversarial_training] 2026-02-16 17:08:34,747 - INFO - Recall: 0.5956
[src.adversarial_training] 2026-02-16 17:08:34,747 - INFO - F1-Score: 0.5987
[src.adversarial_training] 2026-02-16 17:08:34,748 - INFO - Evaluating on adversarial data (epsilon=0.03)...
[src.adversarial_training] 2026-02-16 17:08:43,263 - INFO - Robust Accuracy: 0.2137
[src.adversarial_training] 2026-02-16 17:08:43,263 - INFO - Precision: 0.2915
[src.adversarial_training] 2026-02-16 17:08:43,264 - INFO - Recall: 0.2137
[src.adversarial_training] 2026-02-16 17:08:43,264 - INFO - F1-Score: 0.1968
[src.adversarial_training] 2026-02-16 17:08:43,274 - INFO - Training adversarially robust model...
[src.model] 2026-02-16 17:08:43,275 - INFO - Initializing CNN model...
[src.model] 2026-02-16 17:08:43,284 - INFO - Model created successfully on device: cpu
[src.adversarial_training] 2026-02-16 17:08:43,284 - INFO - Starting adversarial training with epsilon=0.03...
[src.adversarial_training] 2026-02-16 17:09:38,513 - INFO - Epoch [1/5] - Train Loss: 1.6921, Train Acc: 38.27%, Val Loss: 10.9275, Val Acc: 25.48%
[src.adversarial_training] 2026-02-16 17:10:38,328 - INFO - Epoch [2/5] - Train Loss: 1.3845, Train Acc: 50.08%, Val Loss: 25.1256, Val Acc: 19.84%
[src.adversarial_training] 2026-02-16 17:11:33,171 - INFO - Epoch [3/5] - Train Loss: 1.2269, Train Acc: 56.23%, Val Loss: 29.1180, Val Acc: 22.80%
[src.adversarial_training] 2026-02-16 17:12:15,198 - INFO - Epoch [4/5] - Train Loss: 1.1107, Train Acc: 60.37%, Val Loss: 41.7969, Val Acc: 19.13%
[src.adversarial_training] 2026-02-16 17:12:58,599 - INFO - Epoch [5/5] - Train Loss: 0.9959, Train Acc: 64.64%, Val Loss: 45.4011, Val Acc: 21.99%
[src.adversarial_training] 2026-02-16 17:12:58,600 - INFO - Adversarial training completed!
[src.adversarial_training] 2026-02-16 17:12:58,605 - INFO - Evaluating on clean test data...
[src.adversarial_training] 2026-02-16 17:13:03,485 - INFO - Clean Accuracy: 0.2164
[src.adversarial_training] 2026-02-16 17:13:03,485 - INFO - Precision: 0.4687
[src.adversarial_training] 2026-02-16 17:13:03,486 - INFO - Recall: 0.2164
[src.adversarial_training] 2026-02-16 17:13:03,486 - INFO - F1-Score: 0.1803
[src.adversarial_training] 2026-02-16 17:13:03,487 - INFO - Evaluating on adversarial data (epsilon=0.03)...
[src.adversarial_training] 2026-02-16 17:13:12,954 - INFO - Robust Accuracy: 0.5643
[src.adversarial_training] 2026-02-16 17:13:12,954 - INFO - Precision: 0.5744
[src.adversarial_training] 2026-02-16 17:13:12,954 - INFO - Recall: 0.5643
[src.adversarial_training] 2026-02-16 17:13:12,955 - INFO - F1-Score: 0.5629
[src.adversarial_training] 2026-02-16 17:13:12,964 - INFO - Creating defense comparison plot...
[src.adversarial_training] 2026-02-16 17:13:13,444 - INFO - Defense comparison plot saved to results/defense_figures/defense_comparison.png
[src.adversarial_training] 2026-02-16 17:13:13,444 - INFO - Creating adversarial training curves...
[src.adversarial_training] 2026-02-16 17:13:14,223 - INFO - Training curves saved to results/defense_figures/adversarial_training_curves.png
[src.adversarial_training] 2026-02-16 17:13:14,224 - INFO - Saving defense results to file...
[src.adversarial_training] 2026-02-16 17:13:14,226 - INFO - Defense results saved to results/defense_results.txt
[src.adversarial_training] 2026-02-16 17:13:14,232 - INFO - Adversarially trained model saved to results\pth_files\adversarially_trained_model.pth
[src.adversarial_training] 2026-02-16 17:13:14,233 - INFO - Adversarial Training Defense Pipeline Completed!
