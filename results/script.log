[src.model] 2026-02-16 13:56:22,393 - INFO - Starting model creation and summarization...
[src.model] 2026-02-16 13:56:22,393 - INFO - Initializing CNN model...
[src.model] 2026-02-16 13:56:22,400 - INFO - Model created successfully on device: cpu
[src.model] 2026-02-16 13:56:22,400 - INFO - Counting model parameters...
[src.model] 2026-02-16 13:56:22,401 - INFO - Total trainable parameters: 545,098
[src.model] 2026-02-16 13:56:22,401 - INFO - Saving model summary to file...
[src.model] 2026-02-16 13:56:22,402 - INFO - Model summary saved to results/model_summary.txt
[src.model] 2026-02-16 13:56:22,402 - INFO - Model creation and summarization completed!
[src.train_baseline] 2026-02-16 13:56:22,403 - INFO - Starting baseline training pipeline...
[src.train_baseline] 2026-02-16 13:56:22,412 - INFO - Loading CIFAR-10 dataset...
[src.train_baseline] 2026-02-16 13:56:24,374 - INFO - Training samples: 50000
[src.train_baseline] 2026-02-16 13:56:24,375 - INFO - Test samples: 10000
[src.train_baseline] 2026-02-16 13:56:24,375 - INFO - Splitting dataset into train/val/test...
[src.train_baseline] 2026-02-16 13:56:24,380 - INFO - Train size: 35000
[src.train_baseline] 2026-02-16 13:56:24,380 - INFO - Validation size: 7500
[src.train_baseline] 2026-02-16 13:56:24,380 - INFO - Test size: 7500
[src.train_baseline] 2026-02-16 13:56:24,381 - INFO - Creating data loaders...
[src.train_baseline] 2026-02-16 13:56:24,381 - INFO - Batch size: 64
[src.train_baseline] 2026-02-16 13:56:24,382 - INFO - Starting model training...
[src.train_baseline] 2026-02-16 13:56:53,626 - INFO - Epoch [1/5] - Train Loss: 1.3653, Train Acc: 51.32%, Val Loss: 1.0867, Val Acc: 61.77%
[src.train_baseline] 2026-02-16 13:57:22,771 - INFO - Epoch [2/5] - Train Loss: 0.9926, Train Acc: 64.87%, Val Loss: 0.9463, Val Acc: 67.15%
[src.train_baseline] 2026-02-16 13:57:51,150 - INFO - Epoch [3/5] - Train Loss: 0.8347, Train Acc: 70.51%, Val Loss: 0.9110, Val Acc: 68.33%
[src.train_baseline] 2026-02-16 13:58:20,255 - INFO - Epoch [4/5] - Train Loss: 0.7014, Train Acc: 75.51%, Val Loss: 0.8525, Val Acc: 70.56%
[src.train_baseline] 2026-02-16 13:58:49,548 - INFO - Epoch [5/5] - Train Loss: 0.5940, Train Acc: 79.17%, Val Loss: 0.8771, Val Acc: 70.33%
[src.train_baseline] 2026-02-16 13:58:49,549 - INFO - Model training completed!
[src.train_baseline] 2026-02-16 13:58:49,549 - INFO - Evaluating model on test set...
[src.train_baseline] 2026-02-16 13:58:53,091 - INFO - Test Accuracy: 0.6985
[src.train_baseline] 2026-02-16 13:58:53,092 - INFO - Test Precision: 0.7085
[src.train_baseline] 2026-02-16 13:58:53,092 - INFO - Test Recall: 0.6985
[src.train_baseline] 2026-02-16 13:58:53,092 - INFO - Test F1-Score: 0.6957
[src.train_baseline] 2026-02-16 13:58:53,093 - INFO - Saving results to file...
[src.train_baseline] 2026-02-16 13:58:53,095 - INFO - Results saved to results/baseline_results.txt
[src.train_baseline] 2026-02-16 13:58:53,095 - INFO - Saving trained model...
[src.train_baseline] 2026-02-16 13:58:53,114 - INFO - Model saved to results\pth_files\baseline_model.pth
[src.train_baseline] 2026-02-16 13:58:53,114 - INFO - Baseline training pipeline completed!
[src.fgsm_attack] 2026-02-16 13:58:53,127 - INFO - Starting FGSM Attack Pipeline...
[src.model] 2026-02-16 13:58:53,127 - INFO - Initializing CNN model...
[src.model] 2026-02-16 13:58:53,133 - INFO - Model created successfully on device: cpu
[src.fgsm_attack] 2026-02-16 13:58:54,083 - INFO - Testing FGSM with Epsilon = 0.0
[src.fgsm_attack] 2026-02-16 13:58:54,083 - INFO - Generating adversarial examples with epsilon=0.0...
[src.fgsm_attack] 2026-02-16 13:59:02,934 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 13:59:02,934 - INFO - Evaluating FGSM attack with epsilon=0.0...
[src.fgsm_attack] 2026-02-16 13:59:02,972 - INFO - Clean Accuracy: 0.6997
[src.fgsm_attack] 2026-02-16 13:59:02,972 - INFO - Adversarial Accuracy: 0.3151
[src.fgsm_attack] 2026-02-16 13:59:02,973 - INFO - Accuracy Drop: 0.3846
[src.fgsm_attack] 2026-02-16 13:59:02,973 - INFO - Testing FGSM with Epsilon = 0.01
[src.fgsm_attack] 2026-02-16 13:59:02,973 - INFO - Generating adversarial examples with epsilon=0.01...
[src.fgsm_attack] 2026-02-16 13:59:12,049 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 13:59:12,050 - INFO - Evaluating FGSM attack with epsilon=0.01...
[src.fgsm_attack] 2026-02-16 13:59:12,091 - INFO - Clean Accuracy: 0.6997
[src.fgsm_attack] 2026-02-16 13:59:12,092 - INFO - Adversarial Accuracy: 0.2857
[src.fgsm_attack] 2026-02-16 13:59:12,092 - INFO - Accuracy Drop: 0.4140
[src.fgsm_attack] 2026-02-16 13:59:12,152 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 13:59:13,478 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.01.png
[src.fgsm_attack] 2026-02-16 13:59:13,479 - INFO - Testing FGSM with Epsilon = 0.05
[src.fgsm_attack] 2026-02-16 13:59:13,479 - INFO - Generating adversarial examples with epsilon=0.05...
[src.fgsm_attack] 2026-02-16 13:59:22,568 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 13:59:22,569 - INFO - Evaluating FGSM attack with epsilon=0.05...
[src.fgsm_attack] 2026-02-16 13:59:22,604 - INFO - Clean Accuracy: 0.6997
[src.fgsm_attack] 2026-02-16 13:59:22,605 - INFO - Adversarial Accuracy: 0.1919
[src.fgsm_attack] 2026-02-16 13:59:22,605 - INFO - Accuracy Drop: 0.5078
[src.fgsm_attack] 2026-02-16 13:59:22,671 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 13:59:23,942 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.05.png
[src.fgsm_attack] 2026-02-16 13:59:23,943 - INFO - Testing FGSM with Epsilon = 0.1
[src.fgsm_attack] 2026-02-16 13:59:23,943 - INFO - Generating adversarial examples with epsilon=0.1...
[src.fgsm_attack] 2026-02-16 13:59:33,371 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 13:59:33,373 - INFO - Evaluating FGSM attack with epsilon=0.1...
[src.fgsm_attack] 2026-02-16 13:59:33,406 - INFO - Clean Accuracy: 0.6997
[src.fgsm_attack] 2026-02-16 13:59:33,407 - INFO - Adversarial Accuracy: 0.1259
[src.fgsm_attack] 2026-02-16 13:59:33,407 - INFO - Accuracy Drop: 0.5738
[src.fgsm_attack] 2026-02-16 13:59:33,488 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 13:59:34,768 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.1.png
[src.fgsm_attack] 2026-02-16 13:59:34,768 - INFO - Testing FGSM with Epsilon = 0.2
[src.fgsm_attack] 2026-02-16 13:59:34,769 - INFO - Generating adversarial examples with epsilon=0.2...
[src.fgsm_attack] 2026-02-16 13:59:44,129 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 13:59:44,131 - INFO - Evaluating FGSM attack with epsilon=0.2...
[src.fgsm_attack] 2026-02-16 13:59:44,172 - INFO - Clean Accuracy: 0.6997
[src.fgsm_attack] 2026-02-16 13:59:44,172 - INFO - Adversarial Accuracy: 0.0650
[src.fgsm_attack] 2026-02-16 13:59:44,173 - INFO - Accuracy Drop: 0.6347
[src.fgsm_attack] 2026-02-16 13:59:44,239 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 13:59:45,507 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.2.png
[src.fgsm_attack] 2026-02-16 13:59:45,507 - INFO - Creating epsilon analysis plot...
[src.fgsm_attack] 2026-02-16 13:59:45,853 - INFO - Epsilon analysis plot saved to results/fgsm_figures/fgsm_epsilon_analysis.png
[src.fgsm_attack] 2026-02-16 13:59:45,853 - INFO - Saving FGSM results to file...
[src.fgsm_attack] 2026-02-16 13:59:45,855 - INFO - FGSM results saved to results/fgsm_results.txt
[src.fgsm_attack] 2026-02-16 13:59:45,855 - INFO - FGSM Attack Pipeline Completed!
[src.pgd_attack] 2026-02-16 13:59:45,876 - INFO - Starting PGD Attack Pipeline...
[src.model] 2026-02-16 13:59:45,876 - INFO - Initializing CNN model...
[src.model] 2026-02-16 13:59:45,884 - INFO - Model created successfully on device: cpu
[src.pgd_attack] 2026-02-16 13:59:46,865 - INFO - Testing PGD with Epsilon = 0.0
[src.pgd_attack] 2026-02-16 13:59:46,865 - INFO - Generating PGD adversarial examples with epsilon=0.0, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 14:00:36,090 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 14:00:36,091 - INFO - Evaluating PGD attack with epsilon=0.0...
[src.pgd_attack] 2026-02-16 14:00:36,131 - INFO - Clean Accuracy: 0.6997
[src.pgd_attack] 2026-02-16 14:00:36,131 - INFO - Robust Accuracy (PGD): 0.3151
[src.pgd_attack] 2026-02-16 14:00:36,131 - INFO - Accuracy Drop: 0.3846
[src.pgd_attack] 2026-02-16 14:00:36,132 - INFO - Testing PGD with Epsilon = 0.01
[src.pgd_attack] 2026-02-16 14:00:36,132 - INFO - Generating PGD adversarial examples with epsilon=0.01, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 14:01:25,752 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 14:01:25,753 - INFO - Evaluating PGD attack with epsilon=0.01...
[src.pgd_attack] 2026-02-16 14:01:25,788 - INFO - Clean Accuracy: 0.6997
[src.pgd_attack] 2026-02-16 14:01:25,789 - INFO - Robust Accuracy (PGD): 0.2508
[src.pgd_attack] 2026-02-16 14:01:25,789 - INFO - Accuracy Drop: 0.4489
[src.pgd_attack] 2026-02-16 14:01:26,139 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 14:01:27,420 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.01.png
[src.pgd_attack] 2026-02-16 14:01:27,421 - INFO - Testing PGD with Epsilon = 0.03
[src.pgd_attack] 2026-02-16 14:01:27,421 - INFO - Generating PGD adversarial examples with epsilon=0.03, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 14:02:17,083 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 14:02:17,085 - INFO - Evaluating PGD attack with epsilon=0.03...
[src.pgd_attack] 2026-02-16 14:02:17,121 - INFO - Clean Accuracy: 0.6997
[src.pgd_attack] 2026-02-16 14:02:17,121 - INFO - Robust Accuracy (PGD): 0.1520
[src.pgd_attack] 2026-02-16 14:02:17,121 - INFO - Accuracy Drop: 0.5477
[src.pgd_attack] 2026-02-16 14:02:17,440 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 14:02:19,043 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.03.png
[src.pgd_attack] 2026-02-16 14:02:19,043 - INFO - Testing PGD with Epsilon = 0.05
[src.pgd_attack] 2026-02-16 14:02:19,043 - INFO - Generating PGD adversarial examples with epsilon=0.05, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 14:03:08,902 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 14:03:08,904 - INFO - Evaluating PGD attack with epsilon=0.05...
[src.pgd_attack] 2026-02-16 14:03:08,946 - INFO - Clean Accuracy: 0.6997
[src.pgd_attack] 2026-02-16 14:03:08,946 - INFO - Robust Accuracy (PGD): 0.0904
[src.pgd_attack] 2026-02-16 14:03:08,946 - INFO - Accuracy Drop: 0.6093
[src.pgd_attack] 2026-02-16 14:03:09,289 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 14:03:10,535 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.05.png
[src.pgd_attack] 2026-02-16 14:03:10,535 - INFO - Creating PGD epsilon analysis plot...
[src.pgd_attack] 2026-02-16 14:03:10,850 - INFO - PGD epsilon analysis plot saved to results/pgd_figures/pgd_epsilon_analysis.png
[src.pgd_attack] 2026-02-16 14:03:10,850 - INFO - Saving PGD results to file...
[src.pgd_attack] 2026-02-16 14:03:10,852 - INFO - PGD results saved to results/pgd_results.txt
[src.pgd_attack] 2026-02-16 14:03:10,852 - INFO - PGD Attack Pipeline Completed!
[src.poisoning_attack] 2026-02-16 14:03:10,864 - INFO - Starting Data Poisoning Attack Pipeline...
[src.poisoning_attack] 2026-02-16 14:03:10,866 - WARNING - Could not load baseline accuracy, will use 0% poisoning as baseline
[src.poisoning_attack] 2026-02-16 14:03:10,866 - INFO - Testing with 0.0% label poisoning
[src.poisoning_attack] 2026-02-16 14:03:10,866 - INFO - Loading CIFAR-10 with 0.0% poisoning...
[src.poisoning_attack] 2026-02-16 14:03:29,156 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 14:03:29,157 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 14:03:29,157 - INFO - Test size: 7500
[src.model] 2026-02-16 14:03:29,182 - INFO - Initializing CNN model...
[src.model] 2026-02-16 14:03:29,189 - INFO - Model created successfully on device: cpu
[src.poisoning_attack] 2026-02-16 14:03:29,190 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 14:03:58,331 - INFO - Epoch [1/5] - Train Loss: 1.4079, Train Acc: 49.33%, Val Loss: 1.1180, Val Acc: 59.85%
[src.poisoning_attack] 2026-02-16 14:04:27,384 - INFO - Epoch [2/5] - Train Loss: 1.0244, Train Acc: 63.85%, Val Loss: 0.9572, Val Acc: 66.25%
[src.poisoning_attack] 2026-02-16 14:04:56,042 - INFO - Epoch [3/5] - Train Loss: 0.8546, Train Acc: 70.23%, Val Loss: 0.9552, Val Acc: 66.48%
[src.poisoning_attack] 2026-02-16 14:05:25,231 - INFO - Epoch [4/5] - Train Loss: 0.7341, Train Acc: 74.43%, Val Loss: 0.8830, Val Acc: 69.60%
[src.poisoning_attack] 2026-02-16 14:05:54,381 - INFO - Epoch [5/5] - Train Loss: 0.6223, Train Acc: 78.28%, Val Loss: 0.8779, Val Acc: 70.72%
[src.poisoning_attack] 2026-02-16 14:05:54,382 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 14:05:54,382 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 14:05:57,853 - INFO - Test Accuracy: 0.6944
[src.poisoning_attack] 2026-02-16 14:05:57,854 - INFO - Test Precision: 0.7015
[src.poisoning_attack] 2026-02-16 14:05:57,854 - INFO - Test Recall: 0.6944
[src.poisoning_attack] 2026-02-16 14:05:57,854 - INFO - Test F1-Score: 0.6932
[src.poisoning_attack] 2026-02-16 14:05:57,864 - INFO - Model saved to results\pth_files\poisoned_model_0pct.pth
[src.poisoning_attack] 2026-02-16 14:05:57,864 - INFO - Testing with 5.0% label poisoning
[src.poisoning_attack] 2026-02-16 14:05:57,864 - INFO - Loading CIFAR-10 with 5.0% poisoning...
[src.poisoning_attack] 2026-02-16 14:06:15,833 - INFO - Flipping 5.0% of labels...
[src.poisoning_attack] 2026-02-16 14:06:16,080 - INFO - Successfully flipped 1750 labels out of 35000
[src.poisoning_attack] 2026-02-16 14:06:16,082 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 14:06:16,082 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 14:06:16,082 - INFO - Test size: 7500
[src.model] 2026-02-16 14:06:16,095 - INFO - Initializing CNN model...
[src.model] 2026-02-16 14:06:16,103 - INFO - Model created successfully on device: cpu
[src.poisoning_attack] 2026-02-16 14:06:16,104 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 14:06:33,751 - INFO - Epoch [1/5] - Train Loss: 1.5425, Train Acc: 46.59%, Val Loss: 1.1822, Val Acc: 58.36%
[src.poisoning_attack] 2026-02-16 14:06:51,748 - INFO - Epoch [2/5] - Train Loss: 1.2157, Train Acc: 60.44%, Val Loss: 1.0359, Val Acc: 64.09%
[src.poisoning_attack] 2026-02-16 14:07:09,411 - INFO - Epoch [3/5] - Train Loss: 1.0671, Train Acc: 65.92%, Val Loss: 0.9678, Val Acc: 66.39%
[src.poisoning_attack] 2026-02-16 14:07:27,014 - INFO - Epoch [4/5] - Train Loss: 0.9529, Train Acc: 70.39%, Val Loss: 0.9025, Val Acc: 69.57%
[src.poisoning_attack] 2026-02-16 14:07:44,720 - INFO - Epoch [5/5] - Train Loss: 0.8533, Train Acc: 73.67%, Val Loss: 0.9326, Val Acc: 67.87%
[src.poisoning_attack] 2026-02-16 14:07:44,721 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 14:07:44,721 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 14:07:48,218 - INFO - Test Accuracy: 0.6820
[src.poisoning_attack] 2026-02-16 14:07:48,218 - INFO - Test Precision: 0.7056
[src.poisoning_attack] 2026-02-16 14:07:48,219 - INFO - Test Recall: 0.6820
[src.poisoning_attack] 2026-02-16 14:07:48,219 - INFO - Test F1-Score: 0.6852
[src.poisoning_attack] 2026-02-16 14:07:48,232 - INFO - Model saved to results\pth_files\poisoned_model_5pct.pth
[src.poisoning_attack] 2026-02-16 14:07:48,233 - INFO - Testing with 15.0% label poisoning
[src.poisoning_attack] 2026-02-16 14:07:48,233 - INFO - Loading CIFAR-10 with 15.0% poisoning...
[src.poisoning_attack] 2026-02-16 14:08:06,614 - INFO - Flipping 15.0% of labels...
[src.poisoning_attack] 2026-02-16 14:08:06,960 - INFO - Successfully flipped 5250 labels out of 35000
[src.poisoning_attack] 2026-02-16 14:08:06,962 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 14:08:06,962 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 14:08:06,962 - INFO - Test size: 7500
[src.model] 2026-02-16 14:08:07,001 - INFO - Initializing CNN model...
[src.model] 2026-02-16 14:08:07,009 - INFO - Model created successfully on device: cpu
[src.poisoning_attack] 2026-02-16 14:08:07,012 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 14:08:25,279 - INFO - Epoch [1/5] - Train Loss: 1.7736, Train Acc: 40.20%, Val Loss: 1.2919, Val Acc: 56.21%
[src.poisoning_attack] 2026-02-16 14:08:43,171 - INFO - Epoch [2/5] - Train Loss: 1.5156, Train Acc: 52.13%, Val Loss: 1.1633, Val Acc: 63.40%
[src.poisoning_attack] 2026-02-16 14:09:01,058 - INFO - Epoch [3/5] - Train Loss: 1.3931, Train Acc: 57.22%, Val Loss: 1.0417, Val Acc: 65.83%
[src.poisoning_attack] 2026-02-16 14:09:19,468 - INFO - Epoch [4/5] - Train Loss: 1.2910, Train Acc: 61.50%, Val Loss: 1.0709, Val Acc: 66.99%
[src.poisoning_attack] 2026-02-16 14:09:38,097 - INFO - Epoch [5/5] - Train Loss: 1.2040, Train Acc: 64.00%, Val Loss: 1.0326, Val Acc: 67.03%
[src.poisoning_attack] 2026-02-16 14:09:38,097 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 14:09:38,098 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 14:09:41,594 - INFO - Test Accuracy: 0.6579
[src.poisoning_attack] 2026-02-16 14:09:41,595 - INFO - Test Precision: 0.6692
[src.poisoning_attack] 2026-02-16 14:09:41,595 - INFO - Test Recall: 0.6579
[src.poisoning_attack] 2026-02-16 14:09:41,595 - INFO - Test F1-Score: 0.6617
[src.poisoning_attack] 2026-02-16 14:09:41,600 - INFO - Model saved to results\pth_files\poisoned_model_15pct.pth
[src.poisoning_attack] 2026-02-16 14:09:41,600 - INFO - Creating poisoning comparison plot...
[src.poisoning_attack] 2026-02-16 14:09:41,914 - INFO - Poisoning comparison plot saved to results/poisoning_figures/poisoning_comparison.png
[src.poisoning_attack] 2026-02-16 14:09:41,915 - INFO - Creating training curves comparison...
[src.poisoning_attack] 2026-02-16 14:09:42,520 - INFO - Training curves saved to results/poisoning_figures/training_curves.png
[src.poisoning_attack] 2026-02-16 14:09:42,522 - INFO - Saving poisoning results to file...
[src.poisoning_attack] 2026-02-16 14:09:42,524 - INFO - Poisoning results saved to results/poisoning_results.txt
[src.poisoning_attack] 2026-02-16 14:09:42,524 - INFO - Data Poisoning Attack Pipeline Completed!
