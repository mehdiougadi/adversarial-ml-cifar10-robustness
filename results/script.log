[src.model] 2026-02-16 17:41:54,078 - INFO - Starting model creation and summarization...
[src.model] 2026-02-16 17:41:54,079 - INFO - Initializing CNN model...
[src.model] 2026-02-16 17:41:54,084 - INFO - Model created successfully on device: cpu
[src.model] 2026-02-16 17:41:54,085 - INFO - Counting model parameters...
[src.model] 2026-02-16 17:41:54,085 - INFO - Total trainable parameters: 545,098
[src.model] 2026-02-16 17:41:54,085 - INFO - Saving model summary to file...
[src.model] 2026-02-16 17:41:54,086 - INFO - Model summary saved to results/model_summary.txt
[src.model] 2026-02-16 17:41:54,087 - INFO - Model creation and summarization completed!
[src.train_baseline] 2026-02-16 17:41:54,087 - INFO - Starting baseline training pipeline...
[src.train_baseline] 2026-02-16 17:41:54,088 - INFO - Loading CIFAR-10 dataset...
[src.train_baseline] 2026-02-16 17:41:56,054 - INFO - Training samples: 50000
[src.train_baseline] 2026-02-16 17:41:56,054 - INFO - Test samples: 10000
[src.train_baseline] 2026-02-16 17:41:56,054 - INFO - Splitting dataset into train/val/test...
[src.train_baseline] 2026-02-16 17:41:56,059 - INFO - Train size: 35000
[src.train_baseline] 2026-02-16 17:41:56,059 - INFO - Validation size: 7500
[src.train_baseline] 2026-02-16 17:41:56,061 - INFO - Test size: 7500
[src.train_baseline] 2026-02-16 17:41:56,061 - INFO - Creating data loaders...
[src.train_baseline] 2026-02-16 17:41:56,062 - INFO - Batch size: 64
[src.train_baseline] 2026-02-16 17:41:56,063 - INFO - Starting model training...
[src.train_baseline] 2026-02-16 17:42:25,095 - INFO - Epoch [1/5] - Train Loss: 1.4004, Train Acc: 49.83%, Val Loss: 1.1290, Val Acc: 60.13%
[src.train_baseline] 2026-02-16 17:42:54,030 - INFO - Epoch [2/5] - Train Loss: 1.0290, Train Acc: 63.69%, Val Loss: 0.9616, Val Acc: 65.99%
[src.train_baseline] 2026-02-16 17:43:22,317 - INFO - Epoch [3/5] - Train Loss: 0.8572, Train Acc: 69.86%, Val Loss: 0.9218, Val Acc: 67.88%
[src.train_baseline] 2026-02-16 17:43:51,349 - INFO - Epoch [4/5] - Train Loss: 0.7336, Train Acc: 74.20%, Val Loss: 0.8801, Val Acc: 69.97%
[src.train_baseline] 2026-02-16 17:44:20,496 - INFO - Epoch [5/5] - Train Loss: 0.6179, Train Acc: 78.34%, Val Loss: 0.8794, Val Acc: 70.15%
[src.train_baseline] 2026-02-16 17:44:20,497 - INFO - Model training completed!
[src.train_baseline] 2026-02-16 17:44:20,497 - INFO - Evaluating model on test set...
[src.train_baseline] 2026-02-16 17:44:24,023 - INFO - Test Accuracy: 0.6903
[src.train_baseline] 2026-02-16 17:44:24,023 - INFO - Test Precision: 0.6984
[src.train_baseline] 2026-02-16 17:44:24,023 - INFO - Test Recall: 0.6903
[src.train_baseline] 2026-02-16 17:44:24,023 - INFO - Test F1-Score: 0.6892
[src.train_baseline] 2026-02-16 17:44:24,024 - INFO - Saving results to file...
[src.train_baseline] 2026-02-16 17:44:24,026 - INFO - Results saved to results/baseline_results.txt
[src.train_baseline] 2026-02-16 17:44:24,026 - INFO - Saving trained model...
[src.train_baseline] 2026-02-16 17:44:24,033 - INFO - Model saved to results\pth_files\baseline_model.pth
[src.train_baseline] 2026-02-16 17:44:24,033 - INFO - Baseline training pipeline completed!
[src.fgsm_attack] 2026-02-16 17:44:24,044 - INFO - Starting FGSM Attack Pipeline...
[src.fgsm_attack] 2026-02-16 17:44:24,996 - INFO - Testing FGSM with Epsilon = 0.0
[src.fgsm_attack] 2026-02-16 17:44:24,996 - INFO - Generating adversarial examples with epsilon=0.0...
[src.fgsm_attack] 2026-02-16 17:44:33,640 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 17:44:33,641 - INFO - Evaluating FGSM attack with epsilon=0.0...
[src.fgsm_attack] 2026-02-16 17:44:33,667 - INFO - Clean Accuracy: 0.6946
[src.fgsm_attack] 2026-02-16 17:44:33,668 - INFO - Adversarial Accuracy: 0.3545
[src.fgsm_attack] 2026-02-16 17:44:33,668 - INFO - Accuracy Drop: 0.3401
[src.fgsm_attack] 2026-02-16 17:44:33,668 - INFO - Testing FGSM with Epsilon = 0.01
[src.fgsm_attack] 2026-02-16 17:44:33,669 - INFO - Generating adversarial examples with epsilon=0.01...
[src.fgsm_attack] 2026-02-16 17:44:42,444 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 17:44:42,446 - INFO - Evaluating FGSM attack with epsilon=0.01...
[src.fgsm_attack] 2026-02-16 17:44:42,488 - INFO - Clean Accuracy: 0.6946
[src.fgsm_attack] 2026-02-16 17:44:42,488 - INFO - Adversarial Accuracy: 0.3268
[src.fgsm_attack] 2026-02-16 17:44:42,489 - INFO - Accuracy Drop: 0.3678
[src.fgsm_attack] 2026-02-16 17:44:42,543 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 17:44:43,861 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.01.png
[src.fgsm_attack] 2026-02-16 17:44:43,861 - INFO - Testing FGSM with Epsilon = 0.05
[src.fgsm_attack] 2026-02-16 17:44:43,862 - INFO - Generating adversarial examples with epsilon=0.05...
[src.fgsm_attack] 2026-02-16 17:44:52,807 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 17:44:52,809 - INFO - Evaluating FGSM attack with epsilon=0.05...
[src.fgsm_attack] 2026-02-16 17:44:52,849 - INFO - Clean Accuracy: 0.6946
[src.fgsm_attack] 2026-02-16 17:44:52,849 - INFO - Adversarial Accuracy: 0.2263
[src.fgsm_attack] 2026-02-16 17:44:52,850 - INFO - Accuracy Drop: 0.4683
[src.fgsm_attack] 2026-02-16 17:44:52,909 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 17:44:54,139 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.05.png
[src.fgsm_attack] 2026-02-16 17:44:54,140 - INFO - Testing FGSM with Epsilon = 0.1
[src.fgsm_attack] 2026-02-16 17:44:54,140 - INFO - Generating adversarial examples with epsilon=0.1...
[src.fgsm_attack] 2026-02-16 17:45:03,243 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 17:45:03,245 - INFO - Evaluating FGSM attack with epsilon=0.1...
[src.fgsm_attack] 2026-02-16 17:45:03,285 - INFO - Clean Accuracy: 0.6946
[src.fgsm_attack] 2026-02-16 17:45:03,285 - INFO - Adversarial Accuracy: 0.1500
[src.fgsm_attack] 2026-02-16 17:45:03,286 - INFO - Accuracy Drop: 0.5446
[src.fgsm_attack] 2026-02-16 17:45:03,356 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 17:45:04,610 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.1.png
[src.fgsm_attack] 2026-02-16 17:45:04,611 - INFO - Testing FGSM with Epsilon = 0.2
[src.fgsm_attack] 2026-02-16 17:45:04,611 - INFO - Generating adversarial examples with epsilon=0.2...
[src.fgsm_attack] 2026-02-16 17:45:13,661 - INFO - Generated 10000 adversarial examples
[src.fgsm_attack] 2026-02-16 17:45:13,664 - INFO - Evaluating FGSM attack with epsilon=0.2...
[src.fgsm_attack] 2026-02-16 17:45:13,705 - INFO - Clean Accuracy: 0.6946
[src.fgsm_attack] 2026-02-16 17:45:13,705 - INFO - Adversarial Accuracy: 0.0746
[src.fgsm_attack] 2026-02-16 17:45:13,705 - INFO - Accuracy Drop: 0.6200
[src.fgsm_attack] 2026-02-16 17:45:13,777 - INFO - Creating adversarial examples visualization...
[src.fgsm_attack] 2026-02-16 17:45:15,019 - INFO - Visualization saved to results/fgsm_figures/fgsm_examples_eps_0.2.png
[src.fgsm_attack] 2026-02-16 17:45:15,020 - INFO - Creating epsilon analysis plot...
[src.fgsm_attack] 2026-02-16 17:45:15,350 - INFO - Epsilon analysis plot saved to results/fgsm_figures/fgsm_epsilon_analysis.png
[src.fgsm_attack] 2026-02-16 17:45:15,350 - INFO - Saving FGSM results to file...
[src.fgsm_attack] 2026-02-16 17:45:15,352 - INFO - FGSM results saved to results/fgsm_results.txt
[src.fgsm_attack] 2026-02-16 17:45:15,352 - INFO - FGSM Attack Pipeline Completed!
[src.pgd_attack] 2026-02-16 17:45:15,369 - INFO - Starting PGD Attack Pipeline...
[src.pgd_attack] 2026-02-16 17:45:16,299 - INFO - Testing PGD with Epsilon = 0.0
[src.pgd_attack] 2026-02-16 17:45:16,299 - INFO - Generating PGD adversarial examples with epsilon=0.0, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 17:46:03,842 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 17:46:03,842 - INFO - Evaluating PGD attack with epsilon=0.0...
[src.pgd_attack] 2026-02-16 17:46:03,868 - INFO - Clean Accuracy: 0.6946
[src.pgd_attack] 2026-02-16 17:46:03,869 - INFO - Robust Accuracy (PGD): 0.3545
[src.pgd_attack] 2026-02-16 17:46:03,869 - INFO - Accuracy Drop: 0.3401
[src.pgd_attack] 2026-02-16 17:46:03,870 - INFO - Testing PGD with Epsilon = 0.01
[src.pgd_attack] 2026-02-16 17:46:03,870 - INFO - Generating PGD adversarial examples with epsilon=0.01, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 17:46:52,143 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 17:46:52,145 - INFO - Evaluating PGD attack with epsilon=0.01...
[src.pgd_attack] 2026-02-16 17:46:52,176 - INFO - Clean Accuracy: 0.6946
[src.pgd_attack] 2026-02-16 17:46:52,177 - INFO - Robust Accuracy (PGD): 0.2924
[src.pgd_attack] 2026-02-16 17:46:52,177 - INFO - Accuracy Drop: 0.4022
[src.pgd_attack] 2026-02-16 17:46:52,471 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 17:46:53,724 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.01.png
[src.pgd_attack] 2026-02-16 17:46:53,724 - INFO - Testing PGD with Epsilon = 0.03
[src.pgd_attack] 2026-02-16 17:46:53,724 - INFO - Generating PGD adversarial examples with epsilon=0.03, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 17:47:43,080 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 17:47:43,082 - INFO - Evaluating PGD attack with epsilon=0.03...
[src.pgd_attack] 2026-02-16 17:47:43,119 - INFO - Clean Accuracy: 0.6946
[src.pgd_attack] 2026-02-16 17:47:43,120 - INFO - Robust Accuracy (PGD): 0.1861
[src.pgd_attack] 2026-02-16 17:47:43,120 - INFO - Accuracy Drop: 0.5085
[src.pgd_attack] 2026-02-16 17:47:43,460 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 17:47:45,043 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.03.png
[src.pgd_attack] 2026-02-16 17:47:45,044 - INFO - Testing PGD with Epsilon = 0.05
[src.pgd_attack] 2026-02-16 17:47:45,044 - INFO - Generating PGD adversarial examples with epsilon=0.05, alpha=0.01, iterations=10...
[src.pgd_attack] 2026-02-16 17:48:34,280 - INFO - Generated 10000 PGD adversarial examples
[src.pgd_attack] 2026-02-16 17:48:34,282 - INFO - Evaluating PGD attack with epsilon=0.05...
[src.pgd_attack] 2026-02-16 17:48:34,322 - INFO - Clean Accuracy: 0.6946
[src.pgd_attack] 2026-02-16 17:48:34,322 - INFO - Robust Accuracy (PGD): 0.1178
[src.pgd_attack] 2026-02-16 17:48:34,322 - INFO - Accuracy Drop: 0.5768
[src.pgd_attack] 2026-02-16 17:48:34,654 - INFO - Creating PGD adversarial examples visualization...
[src.pgd_attack] 2026-02-16 17:48:35,947 - INFO - PGD visualization saved to results/pgd_figures/pgd_examples_eps_0.05.png
[src.pgd_attack] 2026-02-16 17:48:35,947 - INFO - Creating PGD epsilon analysis plot...
[src.pgd_attack] 2026-02-16 17:48:36,260 - INFO - PGD epsilon analysis plot saved to results/pgd_figures/pgd_epsilon_analysis.png
[src.pgd_attack] 2026-02-16 17:48:36,260 - INFO - Saving PGD results to file...
[src.pgd_attack] 2026-02-16 17:48:36,262 - INFO - PGD results saved to results/pgd_results.txt
[src.pgd_attack] 2026-02-16 17:48:36,262 - INFO - PGD Attack Pipeline Completed!
[src.poisoning_attack] 2026-02-16 17:48:36,273 - INFO - Starting Data Poisoning Attack Pipeline...
[src.poisoning_attack] 2026-02-16 17:48:36,275 - WARNING - Could not load baseline accuracy, will use 0% poisoning as baseline
[src.poisoning_attack] 2026-02-16 17:48:36,275 - INFO - Testing with 0.0% label poisoning
[src.poisoning_attack] 2026-02-16 17:48:36,275 - INFO - Loading CIFAR-10 with 0.0% poisoning...
[src.poisoning_attack] 2026-02-16 17:48:54,681 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 17:48:54,681 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 17:48:54,682 - INFO - Test size: 7500
[src.model] 2026-02-16 17:48:54,709 - INFO - Initializing CNN model...
[src.model] 2026-02-16 17:48:54,762 - INFO - Model created successfully on device: cpu
[src.poisoning_attack] 2026-02-16 17:48:54,768 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 17:49:24,355 - INFO - Epoch [1/5] - Train Loss: 1.4029, Train Acc: 49.85%, Val Loss: 1.0982, Val Acc: 60.95%
[src.poisoning_attack] 2026-02-16 17:49:53,942 - INFO - Epoch [2/5] - Train Loss: 1.0262, Train Acc: 63.92%, Val Loss: 0.9787, Val Acc: 65.36%
[src.poisoning_attack] 2026-02-16 17:50:23,269 - INFO - Epoch [3/5] - Train Loss: 0.8727, Train Acc: 69.37%, Val Loss: 0.9032, Val Acc: 68.08%
[src.poisoning_attack] 2026-02-16 17:50:52,856 - INFO - Epoch [4/5] - Train Loss: 0.7452, Train Acc: 74.01%, Val Loss: 0.8953, Val Acc: 69.15%
[src.poisoning_attack] 2026-02-16 17:51:22,343 - INFO - Epoch [5/5] - Train Loss: 0.6408, Train Acc: 77.65%, Val Loss: 0.8950, Val Acc: 69.63%
[src.poisoning_attack] 2026-02-16 17:51:22,343 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 17:51:22,343 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 17:51:25,789 - INFO - Test Accuracy: 0.6851
[src.poisoning_attack] 2026-02-16 17:51:25,790 - INFO - Test Precision: 0.7064
[src.poisoning_attack] 2026-02-16 17:51:25,790 - INFO - Test Recall: 0.6851
[src.poisoning_attack] 2026-02-16 17:51:25,790 - INFO - Test F1-Score: 0.6895
[src.poisoning_attack] 2026-02-16 17:51:25,800 - INFO - Model saved to results\pth_files\poisoned_model_0pct.pth
[src.poisoning_attack] 2026-02-16 17:51:25,800 - INFO - Testing with 5.0% label poisoning
[src.poisoning_attack] 2026-02-16 17:51:25,800 - INFO - Loading CIFAR-10 with 5.0% poisoning...
[src.poisoning_attack] 2026-02-16 17:51:43,694 - INFO - Flipping 5.0% of labels...
[src.poisoning_attack] 2026-02-16 17:51:43,932 - INFO - Successfully flipped 1750 labels out of 35000
[src.poisoning_attack] 2026-02-16 17:51:43,934 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 17:51:43,934 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 17:51:43,934 - INFO - Test size: 7500
[src.model] 2026-02-16 17:51:43,945 - INFO - Initializing CNN model...
[src.model] 2026-02-16 17:51:43,952 - INFO - Model created successfully on device: cpu
[src.poisoning_attack] 2026-02-16 17:51:43,953 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 17:52:01,320 - INFO - Epoch [1/5] - Train Loss: 1.5425, Train Acc: 46.59%, Val Loss: 1.1822, Val Acc: 58.36%
[src.poisoning_attack] 2026-02-16 17:52:18,851 - INFO - Epoch [2/5] - Train Loss: 1.2157, Train Acc: 60.44%, Val Loss: 1.0359, Val Acc: 64.09%
[src.poisoning_attack] 2026-02-16 17:52:36,590 - INFO - Epoch [3/5] - Train Loss: 1.0671, Train Acc: 65.92%, Val Loss: 0.9678, Val Acc: 66.39%
[src.poisoning_attack] 2026-02-16 17:52:54,261 - INFO - Epoch [4/5] - Train Loss: 0.9529, Train Acc: 70.39%, Val Loss: 0.9025, Val Acc: 69.57%
[src.poisoning_attack] 2026-02-16 17:53:11,702 - INFO - Epoch [5/5] - Train Loss: 0.8533, Train Acc: 73.67%, Val Loss: 0.9326, Val Acc: 67.87%
[src.poisoning_attack] 2026-02-16 17:53:11,703 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 17:53:11,703 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 17:53:15,144 - INFO - Test Accuracy: 0.6820
[src.poisoning_attack] 2026-02-16 17:53:15,144 - INFO - Test Precision: 0.7056
[src.poisoning_attack] 2026-02-16 17:53:15,145 - INFO - Test Recall: 0.6820
[src.poisoning_attack] 2026-02-16 17:53:15,145 - INFO - Test F1-Score: 0.6852
[src.poisoning_attack] 2026-02-16 17:53:15,157 - INFO - Model saved to results\pth_files\poisoned_model_5pct.pth
[src.poisoning_attack] 2026-02-16 17:53:15,158 - INFO - Testing with 15.0% label poisoning
[src.poisoning_attack] 2026-02-16 17:53:15,158 - INFO - Loading CIFAR-10 with 15.0% poisoning...
[src.poisoning_attack] 2026-02-16 17:53:40,222 - INFO - Flipping 15.0% of labels...
[src.poisoning_attack] 2026-02-16 17:53:40,619 - INFO - Successfully flipped 5250 labels out of 35000
[src.poisoning_attack] 2026-02-16 17:53:40,620 - INFO - Train size: 35000
[src.poisoning_attack] 2026-02-16 17:53:40,620 - INFO - Validation size: 7500
[src.poisoning_attack] 2026-02-16 17:53:40,621 - INFO - Test size: 7500
[src.model] 2026-02-16 17:53:40,664 - INFO - Initializing CNN model...
[src.model] 2026-02-16 17:53:40,673 - INFO - Model created successfully on device: cpu
[src.poisoning_attack] 2026-02-16 17:53:40,676 - INFO - Training model on poisoned data...
[src.poisoning_attack] 2026-02-16 17:54:04,646 - INFO - Epoch [1/5] - Train Loss: 1.7736, Train Acc: 40.20%, Val Loss: 1.2919, Val Acc: 56.21%
[src.poisoning_attack] 2026-02-16 17:54:29,335 - INFO - Epoch [2/5] - Train Loss: 1.5156, Train Acc: 52.13%, Val Loss: 1.1633, Val Acc: 63.40%
[src.poisoning_attack] 2026-02-16 17:54:52,118 - INFO - Epoch [3/5] - Train Loss: 1.3931, Train Acc: 57.22%, Val Loss: 1.0417, Val Acc: 65.83%
[src.poisoning_attack] 2026-02-16 17:55:16,110 - INFO - Epoch [4/5] - Train Loss: 1.2910, Train Acc: 61.50%, Val Loss: 1.0709, Val Acc: 66.99%
[src.poisoning_attack] 2026-02-16 17:55:40,101 - INFO - Epoch [5/5] - Train Loss: 1.2040, Train Acc: 64.00%, Val Loss: 1.0326, Val Acc: 67.03%
[src.poisoning_attack] 2026-02-16 17:55:40,101 - INFO - Model training on poisoned data completed!
[src.poisoning_attack] 2026-02-16 17:55:40,103 - INFO - Evaluating poisoned model on clean test set...
[src.poisoning_attack] 2026-02-16 17:55:45,158 - INFO - Test Accuracy: 0.6579
[src.poisoning_attack] 2026-02-16 17:55:45,158 - INFO - Test Precision: 0.6692
[src.poisoning_attack] 2026-02-16 17:55:45,159 - INFO - Test Recall: 0.6579
[src.poisoning_attack] 2026-02-16 17:55:45,159 - INFO - Test F1-Score: 0.6617
[src.poisoning_attack] 2026-02-16 17:55:45,165 - INFO - Model saved to results\pth_files\poisoned_model_15pct.pth
[src.poisoning_attack] 2026-02-16 17:55:45,166 - INFO - Creating poisoning comparison plot...
[src.poisoning_attack] 2026-02-16 17:55:45,660 - INFO - Poisoning comparison plot saved to results/poisoning_figures/poisoning_comparison.png
[src.poisoning_attack] 2026-02-16 17:55:45,660 - INFO - Creating training curves comparison...
[src.poisoning_attack] 2026-02-16 17:55:46,589 - INFO - Training curves saved to results/poisoning_figures/training_curves.png
[src.poisoning_attack] 2026-02-16 17:55:46,590 - INFO - Saving poisoning results to file...
[src.poisoning_attack] 2026-02-16 17:55:46,591 - INFO - Poisoning results saved to results/poisoning_results.txt
[src.poisoning_attack] 2026-02-16 17:55:46,592 - INFO - Data Poisoning Attack Pipeline Completed!
[src.adversarial_training] 2026-02-16 17:55:46,644 - INFO - Starting Adversarial Training Defense Pipeline...
[src.adversarial_training] 2026-02-16 17:55:46,645 - INFO - Loading CIFAR-10 dataset for adversarial training...
[src.adversarial_training] 2026-02-16 17:55:48,004 - INFO - Train size: 35000
[src.adversarial_training] 2026-02-16 17:55:48,005 - INFO - Validation size: 7500
[src.adversarial_training] 2026-02-16 17:55:48,005 - INFO - Test size: 7500
[src.adversarial_training] 2026-02-16 17:55:48,005 - INFO - Evaluating baseline model...
[src.adversarial_training] 2026-02-16 17:55:48,007 - INFO - Evaluating on clean test data...
[src.adversarial_training] 2026-02-16 17:55:52,696 - INFO - Clean Accuracy: 0.6903
[src.adversarial_training] 2026-02-16 17:55:52,697 - INFO - Precision: 0.6984
[src.adversarial_training] 2026-02-16 17:55:52,697 - INFO - Recall: 0.6903
[src.adversarial_training] 2026-02-16 17:55:52,697 - INFO - F1-Score: 0.6892
[src.adversarial_training] 2026-02-16 17:55:52,699 - INFO - Evaluating on adversarial data (epsilon=0.03)...
[src.adversarial_training] 2026-02-16 17:56:01,805 - INFO - Robust Accuracy: 0.2631
[src.adversarial_training] 2026-02-16 17:56:01,805 - INFO - Precision: 0.3186
[src.adversarial_training] 2026-02-16 17:56:01,805 - INFO - Recall: 0.2631
[src.adversarial_training] 2026-02-16 17:56:01,806 - INFO - F1-Score: 0.2240
[src.adversarial_training] 2026-02-16 17:56:01,817 - INFO - Training adversarially robust model...
[src.model] 2026-02-16 17:56:01,817 - INFO - Initializing CNN model...
[src.model] 2026-02-16 17:56:01,827 - INFO - Model created successfully on device: cpu
[src.adversarial_training] 2026-02-16 17:56:01,828 - INFO - Starting adversarial training with epsilon=0.03...
[src.adversarial_training] 2026-02-16 17:57:09,320 - INFO - Epoch [1/5] - Train Loss: 1.1987, Train Acc: 56.49%, Val Loss: 10.6531, Val Acc: 31.53%
[src.adversarial_training] 2026-02-16 17:58:04,075 - INFO - Epoch [2/5] - Train Loss: 1.0025, Train Acc: 64.22%, Val Loss: 22.2713, Val Acc: 25.56%
[src.adversarial_training] 2026-02-16 17:59:00,908 - INFO - Epoch [3/5] - Train Loss: 0.8799, Train Acc: 68.75%, Val Loss: 25.1635, Val Acc: 27.25%
[src.adversarial_training] 2026-02-16 18:00:06,033 - INFO - Epoch [4/5] - Train Loss: 0.7564, Train Acc: 73.40%, Val Loss: 32.5817, Val Acc: 26.81%
[src.adversarial_training] 2026-02-16 18:01:02,671 - INFO - Epoch [5/5] - Train Loss: 0.6457, Train Acc: 77.48%, Val Loss: 36.0203, Val Acc: 26.04%
[src.adversarial_training] 2026-02-16 18:01:02,672 - INFO - Adversarial training completed!
[src.adversarial_training] 2026-02-16 18:01:02,672 - INFO - Evaluating on clean test data...
[src.adversarial_training] 2026-02-16 18:01:07,609 - INFO - Clean Accuracy: 0.2596
[src.adversarial_training] 2026-02-16 18:01:07,610 - INFO - Precision: 0.5155
[src.adversarial_training] 2026-02-16 18:01:07,610 - INFO - Recall: 0.2596
[src.adversarial_training] 2026-02-16 18:01:07,610 - INFO - F1-Score: 0.2217
[src.adversarial_training] 2026-02-16 18:01:07,612 - INFO - Evaluating on adversarial data (epsilon=0.03)...
[src.adversarial_training] 2026-02-16 18:01:17,086 - INFO - Robust Accuracy: 0.5795
[src.adversarial_training] 2026-02-16 18:01:17,086 - INFO - Precision: 0.5971
[src.adversarial_training] 2026-02-16 18:01:17,086 - INFO - Recall: 0.5795
[src.adversarial_training] 2026-02-16 18:01:17,087 - INFO - F1-Score: 0.5823
[src.adversarial_training] 2026-02-16 18:01:17,098 - INFO - Creating defense comparison plot...
[src.adversarial_training] 2026-02-16 18:01:17,572 - INFO - Defense comparison plot saved to results/defense_figures/defense_comparison.png
[src.adversarial_training] 2026-02-16 18:01:17,572 - INFO - Creating adversarial training curves...
[src.adversarial_training] 2026-02-16 18:01:18,304 - INFO - Training curves saved to results/defense_figures/adversarial_training_curves.png
[src.adversarial_training] 2026-02-16 18:01:18,304 - INFO - Saving defense results to file...
[src.adversarial_training] 2026-02-16 18:01:18,306 - INFO - Defense results saved to results/defense_results.txt
[src.adversarial_training] 2026-02-16 18:01:18,313 - INFO - Adversarially trained model saved to results\pth_files\adversarially_trained_model.pth
[src.adversarial_training] 2026-02-16 18:01:18,314 - INFO - Adversarial Training Defense Pipeline Completed!
